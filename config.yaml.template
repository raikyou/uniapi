# 请求 model 时，使用拥有该 model 且 priority 在其中最大的 provider。 provider 有多个时每次请求随机请求
providers:
  - provider: openai # 服务提供商名称, 如 openai、anthropic、gemini、openrouter
    base_url: https://api.openai.com # 后端服务的API地址
    api_key: sk-YgS6GTi0b4bEabc4C # 提供商的API Key
    priority: 0 # 数字越大，优先级越高
    enabled: true # 选填，设置为 false 时手动禁用该 provider，默认启用
    models_endpoint: /v1/models # 选填，未配置 model 列表时将通过此端点向上游请求模型列表，默认 /v1/models
    model: # 选填，如果不配置 model，会自动通过 models_endpoint 指定的端点获取可用的所有模型
      - gpt-4o # 可以使用的模型名称
      - *gemini # 支持任意位置通配符，例如前缀 gemin* 或后缀 *gemini

api_key: sk-KjjI60Yd0JFWtxxxxxxxxxxxxxxwmRWpWpQRo

preferences:
  model_timeout: 20 # 模型超时时间，单位为秒
  cooldown_period: 300 # 渠道冷却时间，单位为秒，默认 300 秒。当模型请求失败时，会自动将该渠道排除冷却一段时间，不再请求该渠道，冷却时间结束后，会自动将该模型恢复，直到再次请求失败，会重新冷却。当 cooldown_period 设置为 0 时，不启用冷却机制。
  proxy: socks5://[username]:[password]@[ip]:[port] # 全局代理地址，选填。
